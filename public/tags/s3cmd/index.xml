<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>S3cmd on My Tech Blog</title>
    <link>https://www.vishnu-tech.com/tags/s3cmd/index.xml</link>
    <description>Recent content in S3cmd on My Tech Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://www.vishnu-tech.com/tags/s3cmd/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>s3cmd Elaborated…</title>
      <link>https://www.vishnu-tech.com/blog/s3cmd-elaborated/</link>
      <pubDate>Sat, 25 May 2013 04:11:02 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/s3cmd-elaborated/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Use –rr option (reduced redundancy) for every put and sync commands !!!. &lt;/strong&gt;
&lt;strong&gt;Use –bucket-location option to mention nearest geographical location to avoid latency.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To view contents inside a bucket&lt;/strong&gt;
#s3cmd ls s3://bucketname&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To copy/sync a directory into a bucket&lt;/strong&gt;
#s3cmd sync Desktop/check s3://bucket_name&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To view all contents of all buckets one level down (only non empty buckets)&lt;/strong&gt;
#s3cmd la -H&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To sync contents of a local dir in a buckter under an existing directory (s3 object)&lt;/strong&gt;
#s3cmd sync Desktop/checkunni/ s3://writingz/check/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To sync remote s3 contents to a local directory&lt;/strong&gt;
#s3cmd sync s3://writingz/check/ Desktop/checkunni/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To sync contents of a local dir in a bucket under a new directory name&lt;/strong&gt;
#s3cmd sync Desktop/checkunni/ s3://homie/newname/
Here newname directory is created on the fly and files of checkunni are copied inside s3://homie/newname&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Copy a non-empty directory (on s3) from one bucket to another bucket&lt;/strong&gt;
#s3cmd -r cp s3://homie/newname s3://writingz/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Copy a non-empty directory (on s3) from one bucket to another bucket under a new name&lt;/strong&gt;
#s3cmd -r cp s3://homie/newname s3://writingz/newname2/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To find the size of a bucket/directory&lt;/strong&gt;
#s3cmd du -H s3://writingz&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To download only a single file&lt;/strong&gt;
#s3cmd get s3://homie/dirname/filename .&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To download a remote directory locally&lt;/strong&gt;.
#s3cmd get -rf s3://writingz/checkunni .
use a / (forward slash) after checkunni to download only the files in it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To upload a single file&lt;/strong&gt;
#s3cmd put PSY.mp3 s3://homie/newname/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To upload a local dir to bucket&lt;/strong&gt;
#s3cmd put -rf s3test s3://homie/newname/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Delete a file&lt;/strong&gt;
#s3cmd del s3://writingz/abc.jpg&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Delete a directory&lt;/strong&gt;
#s3cmd del -rf s3://writingz/check/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Move a file &lt;/strong&gt;(can also be used for rename with files only)****
#s3cmd mv s3://writingz/abc.png s3://haye/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Move a directory to another bucket &lt;/strong&gt;
#s3cmd mv -rf s3://writingz/newname2 s3://haye/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Know the s3cmd version&lt;/strong&gt;
#s3cmd –version&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Make a file public using&lt;/strong&gt;
#s3cmd put –acl-public hangover3.jpg s3://viewzz/abc.jpg&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Make a file private using&lt;/strong&gt;
#s3cmd setacl –acl-private s3://viewzz/hangover3.jpg&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Set all files in a bucket to public/private&lt;/strong&gt;
#s3cmd setacl –acl-public -r s3://writingz/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If an md5 checksum is need to verify files integrity use&lt;/strong&gt;
#sudo s3cmd info s3://viewzz/hangover3.jpg (an amazon s3 object)
#md5sum hangover3.jpg (locally downloaded file from s3)
and compare the checksum value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To delete a bucket (bucket has to be empty use s3cmd del – to delete all files)&lt;/strong&gt;
#s3cmd rb s3://logix.cz-test (use -f option if bucket is non-empty)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Get various information about Buckets or Files&lt;/strong&gt;
#s3cmd info s3://BUCKET[/OBJECT]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Other useful options&lt;/strong&gt;
&lt;strong&gt;–delete-removed&lt;/strong&gt; Delete remote objects with no corresponding local file
[sync]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–no-delete-removed&lt;/strong&gt; Don’t delete remote objects.
&lt;strong&gt;–skip-existing&lt;/strong&gt; Skip over files that exist at the destination (only
for [get] and [sync] commands).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–continue&lt;/strong&gt; Continue getting a partially downloaded file (only for
[get] command).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–reduced-redundancy, –rr&lt;/strong&gt;
Store object with ‘Reduced redundancy’. Lower per-GB
price. [put, cp, mv, sync]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–acl-public&lt;/strong&gt; Store objects with ACL allowing read for anyone.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–acl-private&lt;/strong&gt; Store objects with default ACL allowing access for you&lt;/p&gt;

&lt;p&gt;only.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;–bucket-location=BUCKET_LOCATION &lt;/strong&gt;Datacentre to create bucket in. Eg :  ap-northeast-1  (Tokyo)&lt;/p&gt;

&lt;p&gt;The ACL (Access Control List) of a file can be set at the time of upload using –acl-public or –acl-private options with ‘s3cmd put’ or s3cmd sync’ commands (see below).&lt;/p&gt;

&lt;p&gt;Alternatively the ACL can be altered for existing remote files with ‘s3cmd setacl –acl-public’ (or –acl-private) command.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Additional Links on &lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.raghuramanb.com/2013/01/aws-log-archive-amazon-s3-glacier-part-4.html&#34;&gt;Store S3 objects to Glacier.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://alestic.com/2012/12/s3-glacier-costs&#34;&gt;Consider the costs Glacier could incur during the Transition from S3.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Install &amp; Use s3cmd for S3 Storage</title>
      <link>https://www.vishnu-tech.com/blog/install-use-s3cmd-for-s3-storage/</link>
      <pubDate>Mon, 10 Dec 2012 10:23:24 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/install-use-s3cmd-for-s3-storage/</guid>
      <description>&lt;p&gt;Amazon S3 is a reasonably priced data storage service. Ideal for off-site backups, archiving and other data storage needs. It is generally more reliable than your regular web hosting for storing your files and images. Check out About Amazon S3 section to find out more.&lt;/p&gt;

&lt;p&gt;S3cmd is a command line tool for uploading, retrieving and managing data in Amazon S3. It is best suited for power users who don’t fear command line. It is also ideal for scripts, automated backups triggered from cron, etc.&lt;/p&gt;

&lt;p&gt;S3cmd is an open source project available under GNU Public License v2 (GPLv2) and is free for both commercial and private use. You will only have to pay Amazon for using their storage. None of these money go to S3cmd developers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;#apt-get install s3cmd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To configure s3cmd&lt;/strong&gt;
#s3cmd –configure
[Enter Access Key and Secret Key]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Configuration file is saved into&lt;/strong&gt;
/root/.s3cfg&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To get Help&lt;/strong&gt;
#s3cmd –help&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To List Buckets&lt;/strong&gt;
#s3cmd ls&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To Delete Non-Empty Buckets&lt;/strong&gt;
#s3cmd rb s3://buckt_name -fv&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Copy buckets to local machine&lt;/strong&gt;
#s3cmd get s3://buckt_name -r&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Create Buckets&lt;/strong&gt;
#s3cmd mb s3://buckt_name&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Syncing local dir with s3 Buckets&lt;/strong&gt;
#s3cmd sync local_dir/ s3://buckt_name&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS Products/Solutions – Admins Capsule</title>
      <link>https://www.vishnu-tech.com/blog/aws-productssolutions-admins-capsule/</link>
      <pubDate>Mon, 10 Dec 2012 10:21:57 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/aws-productssolutions-admins-capsule/</guid>
      <description>

&lt;h1 id=&#34;database&#34;&gt;Database&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/running_databases/#rds&#34;&gt;Amazon RDS&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You can think of a &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Welcome.html&#34;&gt;RDS&lt;/a&gt; DB Instance as a database environment in the cloud with the compute and storage resources you specify.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can create and delete DB Instances, define/refine infrastructure attributes of your DB Instance(s), and control access and security via the &lt;a href=&#34;https://console.aws.amazon.com/&#34;&gt;AWS Management Console&lt;/a&gt;, Amazon RDS APIs, and Command Line Tools.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Multiple MySQL databases or SQL Server databases (up to 30) or Oracle database schemas can be created on a given DB Instance.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For optional &lt;a href=&#34;http://aws.amazon.com/rds/faqs/#36&#34;&gt;Multi-AZ deployments&lt;/a&gt; (currently supported for MySQL and Oracle database engines), Amazon RDS also manages synchronous data replication across Availability Zones and automatic failover.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/rds/faqs/&#34;&gt;Amazon RDS FAQs&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;By default, customers are allowed to have up to a total of 20 Amazon RDS DB instances.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/articles/2936?_encoding=UTF8&amp;amp;jiveRedirect=1&#34;&gt;RDS cannot remove storage once it has been allocated. The only way to reduce the amount of storage allocated to a DB Instance is to dump the data out of the DB Instance, create a new DB Instance with less storage space, and load the data into the new DB Instance.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Unlike Multi-AZ deployments, Read Replicas use MySQL’s built-in replication and are subject to its strengths and limitations.This means recent database updates made to a standard (non Multi-AZ) source DB Instance may not be present on associated Read Replicas in the event of an unplanned outage on the source DB Instance. As such, Read Replicas do not offer the same data durability benefits as Multi-AZ deployments. While Read Replicas can provide some read availability benefits, they and are not designed to improve write availability. Read Replicas are currently supported for Amazon RDS for MySQL. They can also be used for serving read traffic when the primary database is unavailable.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The read replica mechanism uses MySQL’s native, asynchronous replication. This means replicas might be lagging behind the master as they try to catch up with writes. The interesting thing about this is that multi-AZ RDS instances apparently use another,_ proprietary type_ of synchronous replication.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A Read Replica will stay active and continue accepting read traffic even after its corresponding source DB Instance has been deleted. If you desire to delete the Read Replica in addition to the source DB Instance, you must explicitly delete the Read Replica using the DeleteDBInstance API or AWS Management Console.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;By default and at no additional charge, Amazon RDS enables automated backups of your DB Instance with a 1 day retention period.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;During the backup window, storage I/O may be suspended while your data is being backed up. This I/O suspension typically lasts a few minutes at most. This I/O suspension is avoided with Multi-AZ DB deployments, since the backup is taken from the standby.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon RDS DB snapshots and automated backups are stored in S3.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you desire to turn off automated backups altogether, you can do so by setting the retention period to 0 (not recommended).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When you delete a DB Instance, you have the ability to specify whether a final DB Snapshot is created upon deletion, which enables a DB Snapshot restore of the deleted database instance at a later date. All previously created DB Snapshots of your DB Instance will be retained and billed at $0.15 per GB-month, unless you choose to delete them.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon RDS does not currently provide access to the binary logs for your Database Instance.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You are not charged for the data transfer incurred in replicating data between your source DB Instance and Read Replica. Billing for a Read Replica begins as soon as the Read Replica has been successfully created (i.e. when status is listed as “active”). The Read Replica will continue being billed at standard Amazon RDS DB Instance hour rates until you issue a command to delete it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon RDS primarily has 3 engines – &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Concepts.DBEngine.MySQL51.html&#34;&gt;Mysql Database Engine&lt;/a&gt;, &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Concepts.DBEngine.Oracle.html&#34;&gt;Oracle Database Engine&lt;/a&gt;,&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Concepts.DBEngine.SQLServer.html&#34;&gt;Microsoft SQL Server Database Engine&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/StartCLI.html&#34;&gt;Setup RDS CLI.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Concepts.DBInstance.html&#34;&gt;RDS Terminology and Concepts.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_ConnectToInstance.html&#34;&gt;How to Connect to RDS – MySQL.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/CommandLineReference/command-reference.html&#34;&gt;RDS CLI – References&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Scenarios.InstanceBasics.html&#34;&gt;Creating and Modifying  DB Instance.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/Scenarios.Backups.html&#34;&gt;Backing UP and Restoring DB Instances.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_ListEvents.html&#34;&gt;Viewing RDS Instance events.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;working with  &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html&#34;&gt;DB Parameter Groups&lt;/a&gt;, &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_WorkingWithSecurityGroups.html&#34;&gt;security groups&lt;/a&gt;, &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_WorkingWithOptionGroups.html&#34;&gt;option groups&lt;/a&gt; &amp;amp; &lt;a href=&#34;http://docs.amazonwebservices.com/AmazonRDS/latest/UserGuide/USER_Monitoring.html&#34;&gt;viewing DB instance metrics&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?messageID=161973&amp;amp;#161973&#34;&gt;RDS Security Best Practices !!!&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?messageID=180752&amp;amp;#180752&#34;&gt;Tech Tips – Scaling Databases with Amazon RDS&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?messageID=160936&amp;amp;#160936&#34;&gt;Tech Tips – On Demand Test Databases&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?messageID=198765&amp;amp;#198765&#34;&gt;Tech Tips IV: Best Practices to Avoid an Inoperable RDS MySQL DB Instance&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://forums.aws.amazon.com/thread.jspa?threadID=56871&amp;amp;tstart=0&#34;&gt;Tech Tips V: Defining CloudWatch alarms for Amazon RDS metrics&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The default storage engine with RDS is InnoDB, but you are free to choose another, like the popular MyISAM. It is important to realize that read replicas on nontransactional storage engines (like MyISAM) require you to freeze your databases, as the consistency cannot be guaranteed when snapshotting. But if you use InnoDB, you are safe, and the only thing you have to do is fire up a new read replica.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;RDS storage is independent of RDS instance classes. Every class can have from 5 GB to 1 TB of storage associated. Scaling up the storage is easy, and you can do it using the Console. It does require a reboot. On the other hand, scaling down the storage is impossible.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/rds/reserved-instances/&#34;&gt;Reserved DB Instances page&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/rds/&#34;&gt;On-Demand DB Instances.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/2928/&#34;&gt;RDS CLI&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://blog.webyog.com/2009/11/16/top-10-things-to-know-about-amazon-rds/&#34;&gt;10 things you should know about RDS.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/running_databases/#dynamodb&#34;&gt;Amazon DynamoDB&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A fast, highly scalable NoSQL database service&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A fully managed service that offers extremely fast performance, seamless scalability and reliability, low cost and more.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=oz-7wJJ9HZ0&#34;&gt;Video&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/running_databases/#simpledb&#34;&gt;Amazon SimpleDB&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A NoSQL database service for smaller datasets.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A fully managed service that provides a schemaless database, reliability and more.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/running_databases/#relational_amis&#34;&gt;Your choice of relational AMIs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A relational database you can manage on your own.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;On Amazon EC2 and EBS that provide scale compute &amp;amp; storage, complete control over instances, and more.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/elasticache/&#34;&gt;Amazon ElastiCache&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Amazon ElastiCache is a web service that makes it easy to deploy, operate, and scale an in-memory cache in the cloud.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/2310261897259567&#34;&gt;Amazon ElasticCache CLI Tool.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;compute&#34;&gt;Compute&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/ec2/&#34;&gt;Amazon Elastic Cloud Compute (EC2)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Amazon Elastic Compute Cloud delivers scalable, pay-as-you-go compute capacity in the cloud.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/ec2/instance-types&#34;&gt;Amazon EC2 Instance Types&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;EBS-Optimized instances are for selected types only such as – Standard Instances(Large,Extra Large), High-Memory Instances(High-Memory Quadruple Extra Large).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Amazon EC2 instances are grouped into seven families: Standard, Micro, High-Memory, High-CPU, Cluster Compute, Cluster GPU, and High I/O.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/351&#34;&gt;Amazon EC2 API (CLI Tools)&lt;/a&gt; and &lt;a href=&#34;http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/SettingUp_CommandLine.html&#34;&gt;how to setup&lt;/a&gt; it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/739&#34;&gt;Simple CLI Access to Amazon EC2 and S3&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/elasticmapreduce/&#34;&gt;Amazon Elastic MapReduce&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon Elastic MapReduce is a web service that enables businesses, researchers, data analysts, and developers to easily and cost-effectively process vast amounts of data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://aws.amazon.com/autoscaling/&#34;&gt;Auto Scaling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Auto Scaling allows you to automatically scale your Amazon EC2 capacity up or down according to conditions you define.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/2535&#34;&gt;Auto Scaling CLI Tool.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;networking&#34;&gt;Networking&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/elasticloadbalancing/&#34;&gt;&lt;strong&gt;Elastic Load Balancing&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/developertools/2536&#34;&gt;ELB API Tools&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Elastic Load Balancing automatically distributes incoming application traffic across multiple Amazon EC2 instances.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>RDS CLI Tools Setup</title>
      <link>https://www.vishnu-tech.com/blog/rds-cli-tools-setup/</link>
      <pubDate>Mon, 10 Dec 2012 10:19:59 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/rds-cli-tools-setup/</guid>
      <description>

&lt;p&gt;#cd /usr/local/rds
#chmod 744 bin/*&lt;/p&gt;

&lt;p&gt;Setup Credentials into the file to use a default AWS Account —
$ cd /usr/local/rds
$ sudo cp credential-file-path.template credential-file
$ sudo vi credential-file
$ sudo chmod 600 /usr/local/aws/rds/credential-file&lt;/p&gt;

&lt;p&gt;Now add to the ~/.bashrc&lt;/p&gt;

&lt;h1 id=&#34;set-location-of-the-ec2-and-rds-command-line-tools&#34;&gt;Set location of the ec2 and rds command line tools&lt;/h1&gt;

&lt;p&gt;export EC2_HOME=/usr
export AWS_RDS_HOME=/usr/local/aws/rds&lt;/p&gt;

&lt;h1 id=&#34;set-aws-path&#34;&gt;Set AWS path&lt;/h1&gt;

&lt;p&gt;export PATH=$PATH:$EC2_HOME/bin:$AWS_RDS_HOME/bin&lt;/p&gt;

&lt;p&gt;Source the .bashrc file —
$ source .bashrc&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&#34;http://domino.symetrikdesign.com/2011/04/28/installing-amazon-rds-command-line-toolkit-on-ubuntu-10-04/&#34;&gt;Reference Link 1&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RDS Sharding &amp; Quick Commands</title>
      <link>https://www.vishnu-tech.com/blog/rds-sharding-quick-commands/</link>
      <pubDate>Mon, 10 Dec 2012 10:17:11 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/rds-sharding-quick-commands/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/articles/0040302286264415#virtualshards&#34;&gt;Source article on RDS sharding by Amazon.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/articles/0040302286264415#virtualshards&#34;&gt;http://aws.amazon.com/articles/0040302286264415#virtualshards&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://searchcloudcomputing.techtarget.com/definition/sharding&#34;&gt;What is sharding?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here unlike ec2 instances there is no rds-db-instance-id instead we use the db-instance names (called as dbinstance_identifiers) in our rds commmands to identify among rds-db-instances.&lt;/p&gt;

&lt;p&gt;Example-
Database Name – news
RDS DB Instances – shard1, shard2&lt;/p&gt;

&lt;p&gt;Consider creating 2 db-shards ie we need 2 db-instance to map those db-shards to db-instances. To reduce the schema setup overhead we use the snapshot and restore capabilities of Amazon RDS to do the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a single “seed” DB Instance.&lt;/li&gt;
&lt;li&gt;Set up the schema on that database.&lt;/li&gt;
&lt;li&gt;Snapshot the database.&lt;/li&gt;
&lt;li&gt;Create more databases from that snapshot using the RDS RestoreDBInstanceFromSnapshot API.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;1.Create SEED DATABASE INSTANCE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#rds-create-db-instance shard1 –engine mysql5.1 –master-username unni –master-user-password 123 –allocated-storage 5 –db-instance-class db.t1.micro –db-name news –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$$output$$
DBINSTANCE  shard1  db.t1.micro  mysql  5  unni  creating  1  ****  n  5.1.63  general-public-license
SECGROUP  default  active
PARAMGRP  default.mysql5.1  in-sync
OPTIONGROUP  default:mysql-5-1  in-sync&lt;/p&gt;

&lt;p&gt;Add IP address to DB Security Group to gain access
1.Find IP from www.whatismyipaddress.com – say its – 122.174.199.204
2.Add the CIDR – 122.174.199.&lt;sup&gt;204&lt;/sup&gt;&amp;frasl;&lt;sub&gt;32&lt;/sub&gt; in the DB-Security Group
3.Try gaining access to rds by – #mysql -h shard1.covaztmm6tup.eu-west-1.rds.amazonaws.com -u unni -p123&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.SETUP SCHEMA ON THE DB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;mysql&amp;gt;show database;
mysql&amp;gt;use news;
mysql&amp;gt;CREATE TABLE articles (
article_id numeric(64,0) NOT NULL PRIMARY KEY,
category char(13),
CHECK category IN (‘BUSINESS’, ‘ENTERTAINMENT’, ‘HEALTH’, ‘SCIENCE’, ‘SPORTS’, ‘TECHNOLOGY’, ‘WORLD’),
title char(128),
submit_time timestamp
);&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.SNAPSHOT and CREATE OTHER DB INSTANCES&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#rds-create-db-snapshot shard1 –db-snapshot-identifier news-seed-database –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$$output$$
DBSNAPSHOT  news-seed-database  shard1  2012-09-04T12:02:30.129Z  mysql  5  creating  unni  5.1.63  general-public-license  manual&lt;/p&gt;

&lt;p&gt;Once the snapshot is available it can be used to create any number of DB Instances. We’re only creating two DB Instances in this example, but it could easily be many more. Also, for our trivial setup, the only efficiency we gain is that we don’t need to create the schema on each. However, in a typical scenario there might be a lot more setup involved in creating the seed (e.g., application configuration data, user accounts, permissions, etc.).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.DB-INSTANCE FROM DB-SNAPSHOT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The following command can be used to create new DB Instances from the seed snapshot:&lt;/p&gt;

&lt;p&gt;_#rds-restore-db-instance-from-db-snapshot shard2 –db-snapshot-identifier news-seed-database –db-instance-class db.t1.micro –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$$output$$
DBINSTANCE  shard2  db.t1.micro  mysql  5  unni  creating  1  n  5.1.63  general-public-license
SECGROUP  default  active
PARAMGRP  default.mysql5.1  in-sync
OPTIONGROUP  default:mysql-5-1  pending&lt;/p&gt;

&lt;p&gt;—————–&lt;/p&gt;

&lt;p&gt;To LIST RDS-INSTANCES
_#rds-describe-db-instances –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;TO DELETE RDS-INSTANCE with FINAL SNAPSHOT
_#rds-delete-db-instance shard1 –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem –final-db-snapshot-identifier shard-final-snapshot&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;TO DELETE RDS-INSTANCE without FINAL SNAPSHOT
_#rds-delete-db-instance shard2 –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem –skip-final-snapshot&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;TO LIST RDS-DB-SNAPSHOTS
_#rds-describe-db-snapshots –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;TO DELETE RDS-DB-SNAPSHOTS
_#rds-delete-db-snapshot shard-final-snapshot –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;NOTE
Creating a final snapshot (before dbinstance termination) incurs additional storage fees.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RDS Scaling</title>
      <link>https://www.vishnu-tech.com/blog/rds-scaling/</link>
      <pubDate>Mon, 10 Dec 2012 07:29:43 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/rds-scaling/</guid>
      <description>&lt;p&gt;If your app gets to the point that you need to start scaling either up or out, it is a good idea to switch to multi-AZ if you don’t run it already. If you have a simple RDS instance, you will degrade your service significantly while scaling, as you can expect to lose the ability to write and/or read. With multi-AZ RDS instances, your service is almost uninterrupted.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scaling Up (or Down)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Scaling up is so easy it is almost ridiculous. The only drawback is that you have some downtime during the operation. If you don’t have multi-AZ enabled, the downtime of your RDS instance could be several minutes, as you have to wait until a new instance is launched and fully functional. For multi-AZ RDS instances, you will experience some downtime as a failover is initiated after the slave has been scaled up (or down). This failover doesn’t take more than a minute most of the time.&lt;/p&gt;

&lt;p&gt;If you initiate a scaling activity via the Console, make sure you enable Apply Immediately if you are in a hurry. If you don’t, scaling will take place during the scheduled maintenance period&lt;/p&gt;

&lt;p&gt;Scaling using the command-line tools is a two-step process. First scale, and then reboot:&lt;/p&gt;

&lt;p&gt;$ rds-modify-db-instance production –db-instance-class db.m1.xlarge –apply-immediately
$ rds-reboot-db-instance production&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scaling Out&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;You can scale out a relational database in two different ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Using read-only slaves (read replicas in AWS)&lt;/li&gt;
&lt;li&gt;Sharding or partitioning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are still some hard problems to solve, as sharding/partitioning has not been addressed yet with RDS. Master-slave type scaling is available, though. A slave, or read replica, is easily created from the Console. The only requirement on the master RDS instance is that backups are not disabled by setting the backup retention period to 0. Currently, you can have up to five read replicas that you have to launch one by one. Amazon is working on the ability to launch multiple replicas at once, but that is not yet available.&lt;/p&gt;

&lt;p&gt;On a multi-AZ RDS instance, launching a read replica goes unnoticed. A snapshot is taken from the standby, the replica is launched, and when it is ready, it starts to catch up with the master. For a normal RDS instance, there is a brief I/O suspension in the order of one minute. AWS advises to use the same instance classes, as differing classes may incur replica lag. With read replicas, you basically introduce eventual consistency in your database (cluster).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ELB and Autoscaling in AWS</title>
      <link>https://www.vishnu-tech.com/blog/elb-and-autoscaling-in-aws/</link>
      <pubDate>Mon, 10 Dec 2012 07:27:56 +0000</pubDate>
      
      <guid>https://www.vishnu-tech.com/blog/elb-and-autoscaling-in-aws/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Installing ELB and Autoscale API tools&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;export AWS_ELB_HOME=/home/users/unni/bashrc/elbtool/ElasticLoadBalancing-1.0.12.0
export PATH=$PATH:$AWS_ELB_HOME/bin
export AWS_AUTO_SCALING_HOME=/home/users/unni/bashrc/auto/AutoScaling-1.0.33.1
export PATH=$PATH:$AWS_AUTO_SCALING_HOME/bin&lt;/p&gt;

&lt;h1 id=&#34;autoscaling&#34;&gt;AUTOSCALING&lt;/h1&gt;

&lt;p&gt;Create AS, Create AS Group and Setup Scaleup Parameter.&lt;/p&gt;

&lt;p&gt;#as-create-launch-config as-agile –region eu-west-1 –image-id ami-b123456 –instance-type t1.micro –key elbtest –group default -K ec2_certs/pk-K4.pem -C ec2_certs/cert-K4.pem&lt;/p&gt;

&lt;p&gt;OK-Created launch config&lt;/p&gt;

&lt;p&gt;_#as-create-auto-scaling-group as-agile-gp –launch-configuration as-agile –region eu-west-1 –availability-zones eu-west-1a,eu-west-1b –min-size 2 –max-size 3 –load-balancers elbtest-agile -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;OK-Created AutoScalingGroup&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;#as-create-or-update-trigger awsauto-nixontr –auto-scaling-group awsauto-nixongp –namespace “AWS/EC2″ –measure CPUUtilization –statistic Average –dimensions “AutoScalingGroupName=awsauto-nixongp” –period 60 –lower-threshold 40 –upper-threshold 80 –lower-breach-increment”=-1″ –upper-breach-increment 1 –breach-duration 1200 -K pk-XN.pem -C cert-XN.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;OK-Created/Updated trigger&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&#34;elastic-load-balancer&#34;&gt;ELASTIC LOAD BALANCER&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Create n Configure ELB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#elb-create-lb elbtest-agile –region eu-west-1 –availability-zones eu-west-1a,eu-west-1b –headers –listener “lb-port=80,instance-port=80,protocol=http” –listener “lb-port=443,instance-port=443,protocol=tcp” -K ec2_certs/pk-KO.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;_DNS_NAME DNS&lt;em&gt;NAME&lt;/em&gt;
_DNS&lt;em&gt;NAME elbtest-agile-1809496912.eu-west-1.elb.amazonaws.com&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;_#elb-configure-healthcheck elbtest-agile –region eu-west-1 –headers –target “HTTP:80/index.html” –interval 5 –timeout 3 –unhealthy-threshold 2 –healthy-threshold 2 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;_HEALTH_CHECK TARGET INTERVAL TIMEOUT HEALTHY_THRESHOLD UNHEALTHY&lt;em&gt;THRESHOLD&lt;/em&gt;
_HEALTH&lt;em&gt;CHECK HTTP:80/index.html 5 3 2 2&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Add Instances to ELB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#elb-register-instances-with-lb elbtest-agile –instances i-A123456 –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To LIST ELBs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;#elb-describe-lbs –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2_certs/cert-K4.pem
LOAD_BALANCER elbtest-agile elbtest-agile-1809496912.eu-west-1.elb.amazonaws.com elbtest-agile-1809496912.eu-west-1.elb.amazonaws.com Z3NF1Z3NOM5OY2 2012-07-19T09:49:19.110Z&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;deletions&#34;&gt; DELETIONS&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;1.Delete Trigger&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;#as-delete-trigger awsauto-nixontrtest –auto-scaling-group awsauto-nixongptest –region eu-west-1&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;DEPRECATED: This command is deprecated and included only to facilitate migration to the new trigger mechanism. You should use this command for migration purposes only.&lt;/p&gt;

&lt;p&gt;Are you sure you want to delete this trigger? [Ny]y
OK-Deleted trigger&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.Set Autoscale to 0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#as-update-auto-scaling-group as-agile-gp –region eu-west-1 –launch-configuration as-agile –min-size 0 –max-size 0 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;OK-Updated AutoScalingGroup&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.Delete Autoscale Group&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#as-delete-auto-scaling-group as-agile-gp –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;OK-Deleted AutoScalingGroup&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.Delete Autoscale Config&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#as-delete-launch-config as-agile –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Are you sure you want to delete this launch configuration? [Ny]y
OK-Deleted launch configuration&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.Finally Delete ELB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;_#elb-delete-lb elbtest-agile –region eu-west-1 -K ec2_certs/pk-K4.pem -C ec2&lt;em&gt;certs/cert-K4.pem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Warning: Deleting a LoadBalancer can lead to service disruption to any
customers connected to the LoadBalancer. Are you sure you want to delete
this LoadBalancer? [Ny]y
OK-Deleting LoadBalancer&lt;/p&gt;

&lt;p&gt;The Following commands will list out Autoscale Related Info —
as-describe-auto-scaling-groups
as-describe-auto-scaling-instances
as-describe-launch-configs
as-describe-triggers [AutoScalingGroupName]&lt;/p&gt;

&lt;h4 id=&#34;references&#34;&gt;References&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.amazonwebservices.com/ElasticLoadBalancing/latest/DeveloperGuide/UsingTheCommandLineTools.html&#34;&gt;AWS Link To Download &amp;amp; Install ELB Command Line&lt;/a&gt;
&lt;a href=&#34;http://aws.amazon.com/elasticloadbalancing/&#34;&gt;ELB Quick Reference Link&lt;/a&gt;
&lt;a href=&#34;http://www.linuxhelp.in/2012/05/amazon-elastic-load-balancing-with.html&#34;&gt;ELB external Reference&lt;/a&gt;
&lt;a href=&#34;http://www.youtube.com/watch?v=8KQ8aLoxVi0&amp;amp;feature=related&#34;&gt;Check Amazon Youtube video on ELB&lt;/a&gt;
&lt;a href=&#34;http://www.youtube.com/watch?v=ainDIPzVM84&#34;&gt;Check Youtube video on Autoscale&lt;/a&gt;
&lt;a href=&#34;http://alestic.com/2012/09/aws-command-line-tools?utm_source=feedburner&amp;amp;utm_medium=feed&amp;amp;utm_campaign=Feed%3A+alestic+%28Alestic.com+-+Ubuntu+on+EC2%29&#34;&gt;Alestic Lists out all AWS Tools download&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>